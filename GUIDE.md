# PsychoPy ì²­ê° Psychophysics ì‹¤í—˜ ê°€ì´ë“œ

PsychoPyë¥¼ ì‚¬ìš©í•˜ì—¬ ì²­ê° ì‹¬ë¦¬ ì‹¤í—˜ì„ êµ¬ì¶•í•˜ê¸° ìœ„í•œ ì™„ë²½í•œ ê°€ì´ë“œì…ë‹ˆë‹¤.

## ğŸ“‹ ëª©ì°¨

1. [ì„¤ì¹˜ ë° ì‹œì‘](#ì„¤ì¹˜-ë°-ì‹œì‘)
2. [í”„ë¡œì íŠ¸ êµ¬ì¡°](#í”„ë¡œì íŠ¸-êµ¬ì¡°)
3. [ê¸°ë³¸ ì‹¤í—˜ í”„ë¡œê·¸ë¨](#ê¸°ë³¸-ì‹¤í—˜-í”„ë¡œê·¸ë¨)
4. [ê³ ê¸‰ ì‹¤í—˜](#ê³ ê¸‰-ì‹¤í—˜)
5. [ìœ í‹¸ë¦¬í‹° ì‚¬ìš©ë²•](#ìœ í‹¸ë¦¬í‹°-ì‚¬ìš©ë²•)
6. [ë°ì´í„° ë¶„ì„](#ë°ì´í„°-ë¶„ì„)
7. [íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)

---

## ì„¤ì¹˜ ë° ì‹œì‘

### ì´ˆê¸° ì„¤ì •

```bash
# Python ê°€ìƒ í™˜ê²½ í™œì„±í™”
source .venv/bin/activate

# íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸
pip install -r requirements.txt
```

### ê¸°ë³¸ ì‹¤í—˜ ì‹¤í–‰

```bash
python experiments/basic_sound_experiment.py
```

---

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
psychopy_program/
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ basic_sound_experiment.py  # ê¸°ë³¸ ìŒí–¥ detection ì‹¤í—˜
â”‚   â”œâ”€â”€ sound_discrimination.py    # ìƒí–¥ì‹ ë°©ë²•ìœ¼ë¡œ ì—­ì¹˜ ì¶”ì • ì‹¤í—˜
â”‚   â””â”€â”€ sound_utilities.py         # ìŒí–¥ ìê·¹ ìƒì„± ë° ë¶„ì„ ìœ í‹¸ë¦¬í‹°
â”œâ”€â”€ data/                          # ì‹¤í—˜ ê²°ê³¼ CSV íŒŒì¼ ì €ì¥
â”œâ”€â”€ stimuli/                       # ìŒì„± íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬
â”œâ”€â”€ .venv/                         # Python 3.11 ê°€ìƒí™˜ê²½
â”œâ”€â”€ README.md                      # í”„ë¡œì íŠ¸ ì„¤ëª…
â”œâ”€â”€ GUIDE.md                       # ì´ íŒŒì¼
â””â”€â”€ requirements.txt               # Python ì˜ì¡´ì„±
```

---

## ê¸°ë³¸ ì‹¤í—˜ í”„ë¡œê·¸ë¨

### ê°œìš”

`experiments/basic_sound_experiment.py`ëŠ” ìŒí–¥ ê°ì§€(Detection) ì‹¤í—˜ì„ ì œê³µí•©ë‹ˆë‹¤.

**ì‹¤í—˜ ì ˆì°¨:**
1. ë‹¤ì–‘í•œ ì£¼íŒŒìˆ˜ì˜ ìŒí–¥ ìê·¹ ì œì‹œ
2. í”¼í—˜ìì˜ ê°ì§€ ë°˜ì‘ ìˆ˜ì§‘
3. ë°˜ì‘ ì‹œê°„ ì¸¡ì •
4. ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥

**ì£¼íŒŒìˆ˜:** 440Hz, 660Hz, 880Hz

### ì‹¤í–‰ ë°©ë²•

```bash
python experiments/basic_sound_experiment.py
```

**GUI ì…ë ¥:**
- **Subject ID**: í”¼í—˜ì ì•„ì´ë”” (ì˜ˆ: S001)
- **Session**: ì„¸ì…˜ ë²ˆí˜¸ (ê¸°ë³¸ê°’: 1)
- **Number of Trials**: ì‹œí–‰ ìˆ˜ (ê¸°ë³¸ê°’: 9)

### ê²°ê³¼ í•´ì„

ìƒì„±ë˜ëŠ” CSV íŒŒì¼ì˜ ì»¬ëŸ¼:

| ì»¬ëŸ¼ | ì„¤ëª… |
|------|------|
| trial_num | ì‹œí–‰ ë²ˆí˜¸ |
| frequency | ìê·¹ ì£¼íŒŒìˆ˜ (Hz) |
| duration | ìê·¹ ì§€ì† ì‹œê°„ (ì´ˆ) |
| volume | ìŒëŸ‰ (0~1) |
| response_detected | ë°˜ì‘ ê°ì§€ ì—¬ë¶€ (True/False) |
| reaction_time | ë°˜ì‘ ì‹œê°„ (ì´ˆ) |
| timestamp | ì‹œê°„ ì •ë³´ |

### ì½”ë“œ ì˜ˆì œ: ê¸°ë³¸ ì‹¤í—˜ ì»¤ìŠ¤í„°ë§ˆì´ì§•

```python
import sys
sys.path.insert(0, 'experiments')
from basic_sound_experiment import ExperimentConfig, SoundExperiment

# ì„¤ì • ìˆ˜ì •
config = ExperimentConfig()
config.frequencies = [500, 1000, 2000]  # ë‹¤ë¥¸ ì£¼íŒŒìˆ˜
config.duration = 0.5  # ìŒí–¥ ì§€ì† ì‹œê°„ ë³€ê²½
config.volume = 0.5  # ìŒëŸ‰ ì¦ê°€
config.num_trials = 15  # ì‹œí–‰ ìˆ˜ ì¦ê°€

# ì‹¤í—˜ ì‹¤í–‰
experiment = SoundExperiment(config)
experiment.run()
```

---

## ê³ ê¸‰ ì‹¤í—˜

### ìŒí–¥ íŒë³„ ì‹¤í—˜ (ìƒí–¥ì‹ ë°©ë²•)

`experiments/sound_discrimination.py`ëŠ” ìƒí–¥ì‹ ë°©ë²•ìœ¼ë¡œ ì£¼íŒŒìˆ˜ ì—­ì¹˜ë¥¼ ì¶”ì •í•©ë‹ˆë‹¤.

**ì‹¤í—˜ ë°©ì‹:**
- **ê¸°ì¤€ìŒ**: ì²˜ìŒ ì œì‹œë˜ëŠ” ìŒ (ê¸°ì¤€)
- **ë¹„êµìŒ**: ë³€í•˜ëŠ” ìŒ (ìƒí–¥ì‹ìœ¼ë¡œ ì¦ê°€)
- **í”¼í—˜ì ê³¼ì œ**: ë¹„êµìŒì´ ê¸°ì¤€ìŒë³´ë‹¤ ë†’ì€ì§€/ë‚®ì€ì§€ íŒë‹¨

**ì—­ì¹˜ ì¶”ì •:**
- í”¼í—˜ìì˜ ë°˜ì‘ì´ ë°”ë€ŒëŠ” ì§€ì  ê°ì§€ (ì—­ì „)
- ë§ˆì§€ë§‰ ì—­ì „ë“¤ì˜ í‰ê· ìœ¼ë¡œ ì—­ì¹˜ ì¶”ì •

### ì‹¤í–‰ ë°©ë²•

```bash
python experiments/sound_discrimination.py
```

**ê²°ê³¼:**
- CSV íŒŒì¼: ê° ì‹œí–‰ì˜ ìê·¹ ì£¼íŒŒìˆ˜ì™€ ë°˜ì‘
- PNG ê·¸ë˜í”„: 
  - ì‹œí–‰ë³„ ì£¼íŒŒìˆ˜ ë³€í™”
  - ë°˜ì‘ ë¶„í¬

---

## ìœ í‹¸ë¦¬í‹° ì‚¬ìš©ë²•

### ìŒí–¥ ìê·¹ ìƒì„±

`sound_utilities.py`ì˜ `ToneGenerator` í´ë˜ìŠ¤ ì‚¬ìš©:

#### 1. ìˆœìŒ(Pure Tone)

```python
from experiments.sound_utilities import ToneGenerator
from psychopy import sound

# 440Hz ìˆœìŒ ìƒì„±
waveform = ToneGenerator.pure_tone(frequency=440, duration=1.0, volume=0.3)

# PsychoPy Sound ê°ì²´ë¡œ ë³€í™˜
psychopy_sound = sound.Sound(waveform, sampleRate=44100)
psychopy_sound.play()
```

#### 2. ìŠ¤ìœ•ìŒ(Sweep Tone) - ì£¼íŒŒìˆ˜ê°€ ë³€í•˜ëŠ” ì†Œë¦¬

```python
# 200Hzì—ì„œ 800Hzë¡œ ë³€í•˜ëŠ” ìŒ
waveform = ToneGenerator.sweep_tone(200, 800, duration=1.0)

psychopy_sound = sound.Sound(waveform, sampleRate=44100)
psychopy_sound.play()
```

#### 3. ë³µí•©ìŒ(Complex Tone) - ì—¬ëŸ¬ ì£¼íŒŒìˆ˜ ì¡°í•©

```python
# ê¸°ë³¸ìŒ(440Hz) + ë°°ìŒë“¤(880Hz, 1320Hz)
waveform = ToneGenerator.complex_tone(
    frequencies=[440, 880, 1320],
    amplitudes=[0.5, 0.3, 0.2],
    duration=1.0
)

psychopy_sound = sound.Sound(waveform, sampleRate=44100)
psychopy_sound.play()
```

#### 4. ë°±ìƒ‰/ë¶„í™ìƒ‰ ì†ŒìŒ

```python
# ë°±ìƒ‰ ì†ŒìŒ
white_noise = ToneGenerator.white_noise(duration=1.0)

# ë¶„í™ìƒ‰ ì†ŒìŒ (ë” ìì—°ìŠ¤ëŸ¬ì›€)
pink_noise = ToneGenerator.pink_noise(duration=1.0)

psychopy_sound = sound.Sound(white_noise, sampleRate=44100)
psychopy_sound.play()
```

### ì‹ í˜¸ ì²˜ë¦¬

`SoundProcessor` í´ë˜ìŠ¤ ì‚¬ìš©:

#### 1. Envelope ì ìš© (ìŒì„± ì‹œì‘/ë ë¶€ë“œëŸ½ê²Œ)

```python
from experiments.sound_utilities import SoundProcessor, ToneGenerator

# ìˆœìŒ ìƒì„±
tone = ToneGenerator.pure_tone(440, 1.0)

# Envelope ì ìš©
processed = SoundProcessor.apply_envelope(
    tone,
    envelope_type='linear',  # 'linear', 'exp', 'hann'
    attack=0.1,    # 100ms ì•ˆë‚´
    release=0.2    # 200ms ì¢…ë£Œ
)
```

#### 2. í•„í„° ì ìš©

```python
# Low-pass filter: 1000Hz ì´ìƒ ì œê±°
filtered = SoundProcessor.apply_filter(
    tone,
    filter_type='lowpass',
    cutoff_freq=1000
)

# Band-pass filter: 400-600Hzë§Œ ìœ ì§€
filtered = SoundProcessor.apply_filter(
    tone,
    filter_type='bandpass',
    cutoff_freq=(400, 600)
)
```

#### 3. ì§„í­ ë³€ì¡°(Amplitude Modulation)

```python
# 5Hzë¡œ ì§„í­ì´ ë³€í•˜ëŠ” ìŒ
modulated = SoundProcessor.apply_amplitude_modulation(
    tone,
    mod_frequency=5,
    mod_depth=0.5
)
```

### ì‹ í˜¸ ë¶„ì„

`SoundAnalyzer` í´ë˜ìŠ¤ ì‚¬ìš©:

```python
from experiments.sound_utilities import SoundAnalyzer

tone = ToneGenerator.pure_tone(440, 1.0)

# ì§€ë°°ì  ì£¼íŒŒìˆ˜ ì°¾ê¸°
dominant_freq = SoundAnalyzer.find_dominant_frequency(tone)
print(f"ì£¼íŒŒìˆ˜: {dominant_freq:.1f}Hz")

# ìŒëŸ‰ ê³„ì‚° (dB)
loudness = SoundAnalyzer.compute_loudness(tone)
print(f"ìŒëŸ‰: {loudness:.1f}dB")

# ìŠ¤í™íŠ¸ëŸ¼ ê³„ì‚°
frequencies, power = SoundAnalyzer.compute_spectrum(tone)

# ì‹œê°í™”
SoundAnalyzer.plot_waveform(tone, title='Pure Tone 440Hz')
SoundAnalyzer.plot_spectrum(tone, title='Power Spectrum')
```

---

## ë¬¸ì¥ ìŒì„± ì´í•´ ì‹¤í—˜ (Sentence Comprehension Experiment)

ë¬¸ì¥ ìŒì„± ì´í•´ ì‹¤í—˜ì€ ê³µê°„ ìŒí–¥(spatial audio)ì„ í™œìš©í•˜ì—¬ í”¼í—˜ìì˜ ìŒì„± ë¬¸ì¥ ì´í•´ ëŠ¥ë ¥ì„ ì¸¡ì •í•˜ëŠ” ê³ ê¸‰ ì‹¤í—˜ì…ë‹ˆë‹¤. ì–‘ìª½ ìŠ¤í”¼ì»¤/í—¤ë“œí°ì—ì„œ ì„œë¡œ ë‹¤ë¥¸ ë¬¸ì¥ì„ ì¬ìƒí•˜ê³ , ê·¸ì— í•´ë‹¹í•˜ëŠ” ê°ê´€ì‹ ë¬¸ì œì— ë‹µí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤.

### ì‹¤í—˜ ì ˆì°¨

**1ë‹¨ê³„: í”¼í—˜ì ì •ë³´ ì…ë ¥**
```python
# í”„ë¡œê·¸ë¨ ì‹œì‘ ì‹œ ë‹¤ìŒ ì •ë³´ ì…ë ¥
- í”¼í—˜ì ID (Subject ID): ì˜ˆ) S001
- ì„¸ì…˜ ë²ˆí˜¸ (Session): ì˜ˆ) 1
- ì‹œì‘ ì‹œê°„ (UTC)ê°€ ìë™ ê¸°ë¡ë¨
```

**2ë‹¨ê³„: ì‹¤í—˜ ì„¤ëª…**
- í™”ë©´ì— ì‹¤í—˜ ì ˆì°¨ ë° ì£¼ì˜ì‚¬í•­ í‘œì‹œ
- "ìŠ¤í˜ì´ìŠ¤ ë°”ë¥¼ ëˆŒëŸ¬ ê³„ì†" ëŒ€ê¸°

**3ë‹¨ê³„: ë¬¸ì¥ ì¬ìƒ ë° ì´í•´ë„ í…ŒìŠ¤íŠ¸**
ê° ì‹œí–‰ë§ˆë‹¤:
- ì¢Œì¸¡(Left) ìŠ¤í”¼ì»¤: ì²« ë²ˆì§¸ ë¬¸ì¥ ì¬ìƒ
- ìš°ì¸¡(Right) ìŠ¤í”¼ì»¤: ë‘ ë²ˆì§¸ ë¬¸ì¥ ì¬ìƒ (ì•½ 0.5ì´ˆ ì§€ì—°)
- ìŒì„± ì¬ìƒ ì™„ë£Œ í›„ 4ì§€ì„ ë‹¤í˜• ë¬¸ì œ í‘œì‹œ
- í”¼í—˜ì ì‘ë‹µ ìˆ˜ì§‘ (1~4 í‚¤ ì…ë ¥)
- ë°˜ì‘ ì‹œê°„(latency) ìë™ ì¸¡ì •

**4ë‹¨ê³„: ê²°ê³¼ ì €ì¥ ë° ì‹œê°í™”**
- CSV íŒŒì¼: `data/{Subject_ID}_session{N}_{timestamp}.csv`
- ê²°ê³¼ ê·¸ë˜í”„: `data/sentence_comprehension_{timestamp}.png` (4ê°œ ê·¸ë˜í”„)

### í€´ì¦ˆ ë°ì´í„° í˜•ì‹ (quiz.xlsx)

í€´ì¦ˆ ë°ì´í„°ëŠ” `quiz.xlsx` íŒŒì¼ì— ì €ì¥ë©ë‹ˆë‹¤:

| ì—´ ì´ë¦„ | ì„¤ëª… | ì˜ˆì‹œ |
|--------|------|------|
| filename | ìŒì„± íŒŒì¼ëª… | Sen_01.wav |
| quiz | ì§ˆë¬¸ í…ìŠ¤íŠ¸ (í•œê¸€) | ì–´ë””ì— ê°€ì„œ ë¬¼ê±´ì„ ìƒ€ë‚˜ìš”? |
| 1 | 1ë²ˆ ì„ íƒì§€ | ë°±í™”ì  |
| 2 | 2ë²ˆ ì„ íƒì§€ | ë§ˆíŠ¸ |
| 3 | 3ë²ˆ ì„ íƒì§€ | ì‹œì¥ |
| 4 | 4ë²ˆ ì„ íƒì§€ | í¸ì˜ì  |
| ì •ë‹µ | ì •ë‹µ (1-4) | 3 |

### ê²°ê³¼ CSV í˜•ì‹

ì‹¤í—˜ ê²°ê³¼ëŠ” ë‹¤ìŒ ì—´ë¡œ ì €ì¥ë©ë‹ˆë‹¤:

```
trial_num        : ì‹œí–‰ ë²ˆí˜¸
total_trials     : ì „ì²´ ì‹œí–‰ ìˆ˜
left_file        : ì¢Œì¸¡ ìŠ¤í”¼ì»¤ ìŒì„± íŒŒì¼ëª…
right_file       : ìš°ì¸¡ ìŠ¤í”¼ì»¤ ìŒì„± íŒŒì¼ëª…
correct_answer   : ì •ë‹µ (1-4)
user_response    : í”¼í—˜ì ì‘ë‹µ (1-4)
is_correct       : ì •ë‹µ ì—¬ë¶€ (True/False)
latency_sec      : ë°˜ì‘ ì‹œê°„ (ì´ˆ)
timestamp        : ì‹¤í—˜ ì‹œê°„ (ISO í˜•ì‹)
```

### ë°ì´í„° ë¶„ì„ ì˜ˆì œ

**1. ê¸°ë³¸ ì„±ëŠ¥ í†µê³„**
```python
import pandas as pd

# ë°ì´í„° ë¡œë“œ
df = pd.read_csv('data/S001_session1_20260207_205636.csv')

# ì •í™•ë„ ì¶œë ¥
accuracy = df['is_correct'].sum() / len(df) * 100
print(f"ì •í™•ë„: {accuracy:.1f}% ({df['is_correct'].sum()}/{len(df)})")

# ë°˜ì‘ì‹œê°„ í†µê³„
print(f"í‰ê·  ë°˜ì‘ì‹œê°„: {df['latency_sec'].mean():.2f}ì´ˆ")
print(f"ìµœì†Œ ë°˜ì‘ì‹œê°„: {df['latency_sec'].min():.2f}ì´ˆ")
print(f"ìµœëŒ€ ë°˜ì‘ì‹œê°„: {df['latency_sec'].max():.2f}ì´ˆ")
```

**2. ì§ˆë¬¸ë³„ ì„±ëŠ¥ ë¶„ì„**
```python
# ê° ì§ˆë¬¸ë³„ ì •í™•ë„
quiz_performance = df.groupby('right_file').agg({
    'is_correct': ['sum', 'count', 'mean']
})
quiz_performance.columns = ['ì •ë‹µìˆ˜', 'ì´ìˆ˜', 'ì •í™•ë„']
print(quiz_performance)
```

**3. ë°˜ì‘ì‹œê°„ ë¶„ì„**
```python
# ì •ë‹µ/ì˜¤ë‹µë³„ ë°˜ì‘ì‹œê°„ ë¹„êµ
correct_latency = df[df['is_correct']]['latency_sec'].mean()
incorrect_latency = df[~df['is_correct']]['latency_sec'].mean()

print(f"ì •ë‹µ ì‹œ í‰ê·  ë°˜ì‘ì‹œê°„: {correct_latency:.2f}ì´ˆ")
print(f"ì˜¤ë‹µ ì‹œ í‰ê·  ë°˜ì‘ì‹œê°„: {incorrect_latency:.2f}ì´ˆ")
```

**4. ì„±ê³¼ ì¶”ì´ ë¶„ì„**
```python
# ì‹œí–‰ ì§„í–‰ì— ë”°ë¥¸ ì„±ê³¼
df['cumulative_correct'] = df['is_correct'].cumsum()
df['cumulative_accuracy'] = df['cumulative_correct'] / (df.index + 1)

import matplotlib.pyplot as plt
plt.figure(figsize=(10, 5))
plt.plot(df.index, df['cumulative_accuracy'])
plt.xlabel('ì‹œí–‰ ë²ˆí˜¸')
plt.ylabel('ëˆ„ì  ì •í™•ë„')
plt.title('ì‹œí–‰ ì§„í–‰ì— ë”°ë¥¸ ì •í™•ë„ ë³€í™”')
plt.grid(True)
plt.show()
```

### ìŒí–¥ ì²˜ë¦¬ ê¸°ìˆ 

ì‹¤í—˜ì€ ë‹¤ìŒ ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ ê³ ìŒì§ˆ ê³µê°„ ìŒí–¥ì„ ì œê³µí•©ë‹ˆë‹¤:

**1. ìŒíŒŒì¼ ë¡œë”© (soundfile)**
```python
import soundfile as sf
audio_data, sample_rate = sf.read('stimuli/audio.wav')
```

**2. ìë™ ì¬ìƒ˜í”Œë§ (scipy.signal.resample)**
- ëª¨ë“  ìŒíŒŒì¼ì€ ìë™ìœ¼ë¡œ 44100 Hzë¡œ ì •ê·œí™”ë¨
- ë‹¤ì–‘í•œ ìƒ˜í”Œìœ¨(22050, 48000, 16000 ë“±) ì§€ì›
- ìŒì§ˆ ì†ìƒ ìµœì†Œí™”

```python
from scipy import signal
resampled = signal.resample(audio_data, int(len(audio_data) * 44100 / original_sr))
```

**3. ìŠ¤í…Œë ˆì˜¤ ì±„ë„ í˜¼í•© (numpy.column_stack)**
```python
import numpy as np
# ì¢Œì¸¡ê³¼ ìš°ì¸¡ ì±„ë„ ê²°í•©
stereo_audio = np.column_stack([left_channel, right_channel])
```

**4. ë°±ê·¸ë¼ìš´ë“œ ì¬ìƒ (sounddevice)**
```python
import sounddevice as sd
# ë¹„ë™ê¸° ì¬ìƒ (í”„ë¡œê·¸ë¨ ê³„ì† ì‹¤í–‰)
stream = sd.play(stereo_audio, samplerate=44100)
```

### ì‹¤í—˜ ì»¤ìŠ¤í„°ë§ˆì´ì§•

**ë³€ìˆ˜ ìˆ˜ì • (experiments/sentence_comprehension.py ìƒë‹¨)**
```python
# ì‹œí–‰ ìˆ˜ ë³€ê²½
num_trials = 20  # ê¸°ë³¸ê°’: 10

# CSV ì €ì¥ ê²½ë¡œ ë³€ê²½
csv_file = 'data/custom_output.csv'

# ìŒì„± í´ë” ê²½ë¡œ ë³€ê²½
stimuli_folder = 'stimuli/'  # ìŒì„± íŒŒì¼ë“¤ì´ ìˆëŠ” í´ë”
```

**ìŒì„± íŒŒì¼ ì¶”ê°€**
1. `stimuli/` í´ë”ì— WAV íŒŒì¼ ë³µì‚¬
2. `quiz.xlsx`ì— í•´ë‹¹ íŒŒì¼ëª… ë° ì§ˆë¬¸ ì¶”ê°€
3. í”„ë¡œê·¸ë¨ ì¬ì‹¤í–‰

**ê·¸ë˜í”„ ì„¤ì • ë³€ê²½**
```python
# plot_results() ë©”ì„œë“œì—ì„œ ìˆ˜ì •:
plt.figure(figsize=(15, 10))  # ê·¸ë˜í”„ í¬ê¸° ë³€ê²½
# ìƒ‰ìƒ ë³€ê²½ (green â†’ blue, etc)
plt.plot(indices, accuracies, color='blue')
```

**ë°˜ì‘ì‹œê°„ ì œí•œ ì¶”ê°€**
```python
# show_quiz() ë©”ì„œë“œ ìˆ˜ì •
max_time = 5.0  # 5ì´ˆ ì œí•œ
if latency_sec > max_time:
    response = 0  # ì‹œê°„ ì´ˆê³¼ ì‹œ ë¬´ì‘ë‹µ ì²˜ë¦¬
```

### ì‹¤í–‰ ë°©ë²•

**ê¸°ë³¸ ì‹¤í–‰**
```bash
cd /Users/yoonseoblim/Documents/Python_Program/psychopy_program
source .venv/bin/activate
python experiments/sentence_comprehension.py
```

**ê²°ê³¼ ë¹ ë¥´ê²Œ í™•ì¸**
```bash
# ìƒì„±ëœ CSV íŒŒì¼ í™•ì¸
ls -la data/S*.csv

# ìƒì„±ëœ ê·¸ë˜í”„ í™•ì¸
ls -la data/sentence_comprehension_*.png
```

---

## ë°ì´í„° ë¶„ì„

### CSV íŒŒì¼ ì½ê¸°

```python
import pandas as pd

# ë°ì´í„° ë¡œë“œ
df = pd.read_csv('data/S001_session1_20260207_120000.csv')

# ê¸°ë³¸ í†µê³„
print(f"ì´ ì‹œí–‰: {len(df)}")
print(f"ê°ì§€ìœ¨: {df['response_detected'].mean():.1%}")
print(f"í‰ê·  ë°˜ì‘ì‹œê°„: {df['reaction_time'].mean():.3f}ì´ˆ")

# ì£¼íŒŒìˆ˜ë³„ ì„±ëŠ¥
performance_by_freq = df.groupby('frequency').agg({
    'response_detected': ['count', 'sum', 'mean'],
    'reaction_time': 'mean'
})
print(performance_by_freq)
```

### ê²°ê³¼ ì‹œê°í™”

```python
import matplotlib.pyplot as plt

# ë°˜ì‘ì‹œê°„ ë¶„í¬
plt.figure(figsize=(10, 5))
plt.hist(df['reaction_time'].dropna(), bins=15)
plt.xlabel('ë°˜ì‘ì‹œê°„ (ì´ˆ)')
plt.ylabel('ë¹ˆë„')
plt.title('ë°˜ì‘ì‹œê°„ ë¶„í¬')
plt.show()

# ì£¼íŒŒìˆ˜ë³„ ê°ì§€ìœ¨
freq_detection = df.groupby('frequency')['response_detected'].mean()
plt.figure(figsize=(10, 5))
freq_detection.plot(kind='bar')
plt.xlabel('ì£¼íŒŒìˆ˜ (Hz)')
plt.ylabel('ê°ì§€ìœ¨')
plt.title('ì£¼íŒŒìˆ˜ë³„ ê°ì§€ìœ¨')
plt.tight_layout()
plt.show()
```

---

## ì»¤ìŠ¤í…€ ì‹¤í—˜ ë§Œë“¤ê¸°

### ì˜ˆì œ: ì§„í­ ì°¨ì´ ì—­ì¹˜(Amplitude Discrimination Threshold) ì‹¤í—˜

```python
from psychopy import visual, sound, event, core, gui, data
import numpy as np
from experiments.sound_utilities import ToneGenerator, SoundProcessor

class AmplitudeDiscriminationExperiment:
    def __init__(self):
        self.window = visual.Window(size=(800, 600), color=[-1, -1, -1])
        self.data = []
    
    def run_trial(self, reference_amplitude, test_amplitude):
        """ê¸°ì¤€ ì§„í­ê³¼ í…ŒìŠ¤íŠ¸ ì§„í­ ë¹„êµ"""
        
        # ìê·¹ ìƒì„±
        ref_tone = ToneGenerator.pure_tone(440, 0.5, volume=reference_amplitude)
        test_tone = ToneGenerator.pure_tone(440, 0.5, volume=test_amplitude)
        
        # ìê·¹ ì œì‹œ
        ref = sound.Sound(ref_tone, sampleRate=44100)
        test = sound.Sound(test_tone, sampleRate=44100)
        
        ref.play()
        core.wait(0.5)
        core.wait(0.3)  # ISI
        test.play()
        core.wait(0.5)
        
        # ë°˜ì‘ ìˆ˜ì§‘
        instructions = visual.TextStim(
            self.window,
            text="ë‘ ë²ˆì§¸ ìŒì´ ë” í¬ë©´ SPACE, ì‘ìœ¼ë©´ Së¥¼ ëˆ„ë¥´ì„¸ìš”",
            color='white'
        )
        instructions.draw()
        self.window.flip()
        
        event.clearEvents()
        response = None
        while response is None:
            keys = event.getKeys(keyList=['space', 's'])
            if 'space' in keys:
                response = 'louder'
            elif 's' in keys:
                response = 'quieter'
            core.wait(0.01)
        
        return {
            'reference_amplitude': reference_amplitude,
            'test_amplitude': test_amplitude,
            'response': response
        }
    
    def run(self, num_trials=20):
        """ì‹¤í—˜ ì‹¤í–‰"""
        ref_amp = 0.3
        
        for trial in range(num_trials):
            # ìƒí–¥ì‹: ì•½ê°„ ë‹¤ë¥¸ ì§„í­ë¶€í„° ì‹œì‘
            test_amp = ref_amp + (trial * 0.02)
            
            result = self.run_trial(ref_amp, test_amp)
            self.data.append(result)
        
        self.window.close()
        
        # ë°ì´í„° ì €ì¥
        import pandas as pd
        df = pd.DataFrame(self.data)
        df.to_csv('data/amplitude_discrimination.csv', index=False)

# ì‹¤í—˜ ì‹¤í–‰
if __name__ == '__main__':
    exp = AmplitudeDiscriminationExperiment()
    exp.run()
```

---

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ: ì†Œë¦¬ê°€ ë“¤ë¦¬ì§€ ì•ŠìŒ

**í•´ê²°ì±…:**
1. ì‹œìŠ¤í…œ ìŒëŸ‰ í™•ì¸
2. ìŠ¤í”¼ì»¤/í—¤ë“œí° ì—°ê²° í™•ì¸
3. ì½”ë“œì—ì„œ `volume` ê°’ ì¦ê°€:
   ```python
   config.volume = 0.8  # 0~1 ë²”ìœ„
   ```

### ë¬¸ì œ: GUI ëŒ€í™”ìƒìê°€ ë‚˜íƒ€ë‚˜ì§€ ì•ŠìŒ

**í•´ê²°ì±…:**
- macOS: ê¶Œí•œ ì„¤ì • í™•ì¸
- ë˜ëŠ” ì½”ë“œì—ì„œ ì§ì ‘ ì„¤ì •:
  ```python
  config = ExperimentConfig()
  config.subject_id = 'S001'
  experiment = SoundExperiment(config)
  experiment.run()
  ```

### ë¬¸ì œ: CSV íŒŒì¼ì´ ì €ì¥ë˜ì§€ ì•ŠìŒ

**í•´ê²°ì±…:**
1. `data/` ë””ë ‰í† ë¦¬ ì¡´ì¬ í™•ì¸ (ìë™ ìƒì„±ë¨)
2. ì“°ê¸° ê¶Œí•œ í™•ì¸:
   ```bash
   ls -la data/
   ```

### ë¬¸ì œ: PsychoPy ê´€ë ¨ ì˜¤ë¥˜

**í•´ê²°ì±…:**
```bash
# ê°€ìƒí™˜ê²½ ì¬í™œì„±í™”
source .venv/bin/activate

# PsychoPy ì¬ì„¤ì¹˜
pip install --upgrade psychopy
```

---

## ì°¸ê³  ìë£Œ

- [PsychoPy ê³µì‹ ë¬¸ì„œ](https://www.psychopy.org/)
- [PsychoPy API ë ˆí¼ëŸ°ìŠ¤](https://www.psychopy.org/api/)
- [ì²­ê° ì‹ í˜¸ ì²˜ë¦¬](https://en.wikipedia.org/wiki/Digital_signal_processing)

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸:** 2026ë…„ 2ì›” 7ì¼
